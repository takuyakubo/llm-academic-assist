# 文書処理モジュール概要

## 1. 目的と概要

文書処理モジュールは、LLM学術文書支援システムにおいてPDFや画像形式の学術文書を取り込み、解析して構造化するための中核コンポーネントです。このモジュールは以下の主要機能を提供します：

1. PDFおよび画像からのテキスト抽出
2. 文書構造の解析と階層化（章・節・項の識別）
3. 数式の認識とLaTeX形式への変換
4. 図表の認識と抽出
5. テキスト・数式・図表間の参照関係の抽出
6. OCRによる画像テキストの認識
7. 処理済み文書の構造化保存とインデックス作成

## 2. アーキテクチャ概要

```
┌─────────────────────────────────────────────────────────┐
│                  文書処理モジュール                      │
│                                                         │
│  ┌───────────────┐  ┌───────────────┐  ┌───────────────┐│
│  │   ファイル    │  │  テキスト     │  │    構造      ││
│  │  プロセッサー  │  │  エクストラクタ │  │  アナライザー ││
│  └───────┬───────┘  └───────┬───────┘  └───────┬───────┘│
│          │                  │                  │        │
│          ▼                  ▼                  ▼        │
│  ┌───────────────┐  ┌───────────────┐  ┌───────────────┐│
│  │   数式認識    │  │   図表認識    │  │ 文書インデクサー││
│  │               │  │               │  │               ││
│  └───────────────┘  └───────────────┘  └───────────────┘│
└─────────────────────────────────────────────────────────┘
            │                                  ▲
            │                                  │
            ▼                                  │
┌─────────────────────────┐       ┌─────────────────────────┐
│                         │       │                         │
│   ストレージシステム    │       │    データベース        │
│  (S3, ローカルストレージ)│       │    (MongoDB)          │
└─────────────────────────┘       └─────────────────────────┘
```

## 3. 主要コンポーネント

### 3.1 ファイルプロセッサー

アップロードされたファイルの初期処理を担当するコンポーネントです。

**主な責務**:
- ファイル形式の検証と識別（PDF, JPG, PNG等）
- ファイルのサニタイズと前処理
- ストレージへの保存と一意識別子の割り当て
- ファイルメタデータの抽出（ページ数、作成日時など）
- 処理パイプラインの初期化と調整

### 3.2 テキストエクストラクタ

PDFや画像からテキストを抽出するコンポーネントです。

**主な責務**:
- PDFからのテキスト層抽出
- フォントと文字スタイルの処理
- テキスト位置情報の保持
- 段組みとレイアウトの認識
- PDFにテキスト層がない場合のOCR連携

### 3.3 構造アナライザー

抽出されたテキストから文書の論理構造を解析するコンポーネントです。

**主な責務**:
- 章・節・項などの見出し検出と階層化
- 段落と文の境界認識
- リスト構造の検出（箇条書き、番号付きリスト）
- 参考文献セクションの識別
- 文書の論理フローの解析

### 3.4 数式認識

文書内の数式を検出し、LaTeX形式に変換するコンポーネントです。

**主な責務**:
- インライン数式と表示数式の検出
- 数式のLaTeX形式への変換
- 数式内の変数と記号の認識
- 複雑な数式のセグメンテーション
- 数式の位置情報と周辺テキストとの関連付け

### 3.5 図表認識

文書内の図表を検出し、メタデータを抽出するコンポーネントです。

**主な責務**:
- 図や表の位置検出
- 図表キャプションの抽出
- 表構造の解析とデータ抽出
- 図表番号の認識
- 図表と本文の参照関係の抽出

### 3.6 文書インデクサー

処理された文書情報をデータベースに格納し、検索インデックスを作成するコンポーネントです。

**主な責務**:
- 構造化データのデータベース保存
- 全文検索インデックスの作成
- ベクトル埋め込みの生成
- メタデータインデックスの構築
- 効率的な検索と取得のための最適化

## 4. 主要機能

### 4.1 PDFテキスト抽出

PDFからテキストを高精度で抽出する機能です。

**機能詳細**:
- PDFのテキスト層からの直接抽出
- フォント情報と文字スタイルの保持
- 複雑なレイアウト（複数列、テキストボックス）の処理
- ページ番号、ヘッダー、フッターの識別
- テキスト抽出が困難なPDFに対するフォールバック戦略

**実装アプローチ**:
- PyMuPDF (fitz)を主要エンジンとして使用
- PDFMinerをセカンダリエンジンとして使用
- 抽出結果の品質評価と最適エンジンの自動選択
- 複数エンジンの結果統合による精度向上

### 4.2 文書構造解析

テキストから文書の論理構造を解析する機能です。

**機能詳細**:
- 見出しパターンの認識（番号付き、装飾付き見出し）
- 階層レベルの特定（章、節、小節など）
- 段落境界の検出
- 箇条書きと番号付きリストの認識
- 図表参照と引用の検出

**実装アプローチ**:
- 正規表現ベースのパターンマッチング
- 機械学習モデルによる見出し分類
- ルールベースと学習ベースのハイブリッドアプローチ
- フォントサイズとスタイル情報の活用（利用可能な場合）

**見出し検知例**:
```python
def detect_headings(text):
    # 様々な見出しパターンを検出
    heading_patterns = [
        # 第1章、1.1 などの見出しパターン
        r'^(?:第)?(\d+)(?:章|節)\s+(.+?)$',
        # 1. Introduction などの見出しパターン
        r'^(\d+(?:\.\d+)*)\s+(.+?)$',
        # Chapter 1: Introduction などの見出しパターン
        r'^(?:Chapter|Section)\s+(\d+(?:\.\d+)*)(?:\:|\.\s+)(.+?)$'
    ]
    
    headings = []
    for line in text.split('\n'):
        for pattern in heading_patterns:
            match = re.match(pattern, line.strip())
            if match:
                number = match.group(1)
                title = match.group(2)
                # 階層レベルを推定
                level = len(number.split('.'))
                headings.append({
                    'number': number,
                    'title': title,
                    'level': level,
                    'text': line.strip()
                })
                break
    
    return headings
```

### 4.3 数式認識と変換

文書内の数式を検出してLaTeX形式に変換する機能です。

**機能詳細**:
- インライン数式と表示数式の検出
- 数式画像のセグメンテーション
- OCRと特殊なパターン認識による数式解析
- LaTeX形式への変換
- 数式の意味的解釈（オプション）

**実装アプローチ**:
- MathpixのAPIによる数式認識
- 独自の数式OCRモデル（YOLOベース）
- 数式のセグメンテーションと認識の2段階アプローチ
- LaTeX形式の正規化と標準化

**使用例**:
```python
async def extract_equations(pdf_path, page_range=None):
    """PDFから数式を抽出しLaTeX形式に変換"""
    # PDFを画像に変換
    images = convert_pdf_to_images(pdf_path, page_range)
    equations = []
    
    for i, img in enumerate(images):
        page_num = i if page_range is None else page_range[i]
        
        # 数式領域を検出
        equation_regions = detect_equation_regions(img)
        
        for region in equation_regions:
            # 領域を切り出し
            eq_image = crop_image(img, region)
            
            # MathpixAPIで認識
            latex = await recognize_equation_with_mathpix(eq_image)
            
            # 結果を保存
            equations.append({
                'page': page_num,
                'bbox': region,
                'latex': latex,
                'type': determine_equation_type(region, img.shape)
            })
    
    return equations
```

### 4.4 図表認識と抽出

文書内の図や表を認識し、メタデータを抽出する機能です。

**機能詳細**:
- 図表の位置検出
- 図表キャプションの抽出と関連付け
- 表構造の解析とデータ抽出
- 図の内容分類
- 図表と本文中の参照の関連付け

**実装アプローチ**:
- コンピュータビジョンによる図表検出（YOLOv5/Faster R-CNN）
- OCRによるキャプション抽出
- 表構造認識のための特殊アルゴリズム
- 図表参照パターンの検出と照合

**図表検出例**:
```python
def detect_figures_and_tables(pdf_path):
    """PDFから図表を検出"""
    # PDFを画像に変換
    images = convert_pdf_to_images(pdf_path)
    figures_and_tables = []
    
    # 図表検出モデルをロード
    model = load_detection_model('figure_table_detection.pt')
    
    for i, img in enumerate(images):
        # 検出実行
        detections = model(img)
        
        for det in detections:
            bbox, class_id, conf = det
            
            item = {
                'page': i,
                'bbox': bbox,
                'type': 'figure' if class_id == 0 else 'table',
                'confidence': conf
            }
            
            # キャプションを検出
            caption = detect_caption(img, bbox)
            if caption:
                item['caption'] = caption
                
                # 図表番号を抽出
                number_match = re.search(r'(図|表|Fig\.|Table)\s*(\d+\.\d+|\d+)', caption)
                if number_match:
                    item['number'] = number_match.group(2)
                    item['label'] = number_match.group(1)
            
            figures_and_tables.append(item)
    
    return figures_and_tables
```

### 4.5 OCR処理

画像ベースの文書やスキャンPDFからテキストを認識する機能です。

**機能詳細**:
- 画像のテキスト領域検出
- 文字認識と言語判定
- 低品質画像の前処理と強化
- レイアウト保持と段組み認識
- テキストの正規化と後処理

**実装アプローチ**:
- Tesseract OCRをベースエンジンとして使用
- OCRの前処理（デスキュー、ノイズ除去、コントラスト調整）
- 文字認識精度を高めるための画像最適化
- 精度向上のための言語モデル適用

**使用例**:
```python
def perform_ocr(image_path, language='eng+jpn'):
    """OCRを実行してテキストを抽出"""
    # 画像を読み込み
    image = cv2.imread(image_path)
    
    # 前処理
    processed_image = preprocess_for_ocr(image)
    
    # OCR実行
    ocr_result = pytesseract.image_to_data(
        processed_image, 
        lang=language,
        output_type=pytesseract.Output.DICT,
        config='--psm 1 --oem 3'
    )
    
    # 結果の構造化
    text_blocks = []
    current_block = {'text': [], 'bbox': None, 'conf': 0}
    
    for i in range(len(ocr_result['text'])):
        if ocr_result['text'][i].strip():
            x = ocr_result['left'][i]
            y = ocr_result['top'][i]
            w = ocr_result['width'][i]
            h = ocr_result['height'][i]
            conf = ocr_result['conf'][i]
            
            current_block['text'].append(ocr_result['text'][i])
            current_block['conf'] += conf
            
            if current_block['bbox'] is None:
                current_block['bbox'] = [x, y, x+w, y+h]
            else:
                current_block['bbox'][0] = min(current_block['bbox'][0], x)
                current_block['bbox'][1] = min(current_block['bbox'][1], y)
                current_block['bbox'][2] = max(current_block['bbox'][2], x+w)
                current_block['bbox'][3] = max(current_block['bbox'][3], y+h)
        
        elif current_block['text']:
            current_block['text'] = ' '.join(current_block['text'])
            current_block['conf'] /= len(current_block['text'].split())
            text_blocks.append(current_block)
            current_block = {'text': [], 'bbox': None, 'conf': 0}
    
    # 最後のブロックを追加
    if current_block['text']:
        current_block['text'] = ' '.join(current_block['text'])
        current_block['conf'] /= len(current_block['text'].split())
        text_blocks.append(current_block)
    
    return text_blocks
```

### 4.6 インデックス作成

処理された文書を構造化保存し、効率的な検索のためのインデックスを作成する機能です。

**機能詳細**:
- 全文検索インデックスの構築
- セクションレベルでのベクトル埋め込み生成
- メタデータに基づくインデックス作成
- 数式検索のための特殊インデックス
- 図表内容のインデックス化

**実装アプローチ**:
- ElasticsearchやMongoDB Atlasの検索機能を活用
- セマンティック検索のためのテキスト埋め込み生成
- 数式検索のための特殊なトークン化と類似性計算
- 階層構造を考慮したインデックス設計

**インデックス作成例**:
```python
async def create_document_indexes(document_id, processed_content):
    """文書のインデックスを作成"""
    # ドキュメントメタデータ
    doc_metadata = {
        'id': document_id,
        'title': processed_content['title'],
        'author': processed_content['author'],
        'publication_date': processed_content['publication_date'],
        'language': processed_content['language'],
        'processed_date': datetime.now()
    }
    
    # MongoDBにメタデータを保存
    await db.documents.insert_one(doc_metadata)
    
    # セクションデータの保存とインデックス作成
    section_records = []
    vector_records = []
    
    for section in processed_content['sections']:
        # セクションレコード
        section_record = {
            'document_id': document_id,
            'section_id': section['id'],
            'title': section['title'],
            'level': section['level'],
            'parent_id': section.get('parent_id'),
            'content': section['content'],
            'page_range': section['page_range']
        }
        section_records.append(section_record)
        
        # ベクトル埋め込みの生成
        if len(section['content']) > 10:
            embedding = await generate_text_embedding(section['content'])
            vector_record = {
                'document_id': document_id,
                'section_id': section['id'],
                'vector': embedding
            }
            vector_records.append(vector_record)
    
    # セクションデータ一括挿入
    if section_records:
        await db.sections.insert_many(section_records)
    
    # ベクトルデータ一括挿入
    if vector_records:
        await db.vector_embeddings.insert_many(vector_records)
    
    # Elasticsearchのインデックス更新
    await update_elasticsearch_index(document_id, processed_content)
    
    return {
        'document_id': document_id,
        'section_count': len(section_records),
        'vector_count': len(vector_records)
    }
```

## 5. 処理パイプライン

文書のアップロードから構造化完了までの処理フローです。

### 5.1 処理フロー概要

```
ファイルアップロード → 前処理 → テキスト抽出 → 構造解析 → 並行処理(数式認識, 図表認識, OCR) → 後処理 → インデックス作成 → 完了通知
```

### 5.2 詳細フロー

1. **ファイルアップロード**
   - ファイルタイプ検証
   - ウイルスチェック
   - 一時ストレージへの保存
   - 処理ジョブの作成

2. **前処理**
   - ファイルメタデータ抽出
   - ページ数カウント
   - 処理戦略決定（テキスト抽出 vs OCR）
   - 処理リソース割り当て

3. **テキスト抽出**
   - PDFテキスト層からの抽出
   - レイアウト解析
   - テキスト位置情報保持
   - 初期クリーニング

4. **構造解析**
   - 階層構造検出
   - 見出し認識
   - セクション分割
   - 相互参照解析

5. **並行処理**
   - **数式認識**: 数式検出 → 変換 → 検証
   - **図表認識**: 位置検出 → キャプション抽出 → 内容分析
   - **OCR処理**: テキスト層のない部分に適用

6. **後処理**
   - データ統合
   - クロスリファレンス解決
   - エラーチェックと補正
   - メタデータ充実

7. **インデックス作成**
   - データベース保存
   - 検索インデックス構築
   - ベクトル埋め込み生成
   - 文書キャッシュ最適化

8. **完了通知**
   - 処理結果サマリー生成
   - ユーザーへの通知
   - 処理統計の記録

### 5.3 非同期処理実装

長時間かかる文書処理を効率的に実行するための非同期処理アプローチです。

**実装例**:
```python
async def process_document(document_id, file_path, file_type, user_id):
    """文書処理の全体フロー（非同期）"""
    try:
        # 処理ステータス更新
        await update_processing_status(document_id, 'started')
        
        # 1. 前処理
        metadata = await preprocess_document(file_path, file_type)
        await update_processing_status(document_id, 'preprocessing_completed', metadata)
        
        # 2. テキスト抽出
        if file_type == 'pdf':
            text_result = await extract_text_from_pdf(file_path)
        else:
            # 画像の場合はOCRを使用
            text_result = await perform_ocr_on_image(file_path)
        
        await update_processing_status(document_id, 'text_extraction_completed')
        
        # 3. 構造解析
        structure = await analyze_document_structure(text_result)
        await update_processing_status(document_id, 'structure_analysis_completed')
        
        # 4. 並行処理タスクの作成
        tasks = []
        
        # 数式認識タスク
        tasks.append(extract_equations(file_path, structure))
        
        # 図表認識タスク
        tasks.append(detect_figures_and_tables(file_path))
        
        # 必要に応じてOCR処理タスク
        if metadata.get('requires_ocr', False):
            tasks.append(perform_additional_ocr(file_path))
        
        # 並行処理の実行と結果収集
        equation_result, figure_table_result, *ocr_result = await asyncio.gather(*tasks)
        
        # 5. 後処理と統合
        integrated_result = await integrate_processing_results(
            document_id,
            text_result,
            structure,
            equation_result,
            figure_table_result,
            ocr_result[0] if ocr_result else None
        )
        
        await update_processing_status(document_id, 'integration_completed')
        
        # 6. インデックス作成
        index_result = await create_document_indexes(document_id, integrated_result)
        await update_processing_status(document_id, 'indexing_completed', index_result)
        
        # 7. 完了
        await update_processing_status(document_id, 'completed', {
            'processing_time': calculate_processing_time(document_id),
            'sections_count': len(structure['sections']),
            'equations_count': len(equation_result),
            'figures_tables_count': len(figure_table_result)
        })
        
        # 8. ユーザー通知
        await notify_user(user_id, document_id, 'processing_completed')
        
        return {
            'status': 'success',
            'document_id': document_id
        }
        
    except Exception as e:
        logger.error(f"Document processing error: {str(e)}", exc_info=True)
        await update_processing_status(document_id, 'error', {'error': str(e)})
        await notify_user(user_id, document_id, 'processing_error', {'error': str(e)})
        
        return {
            'status': 'error',
            'document_id': document_id,
            'error': str(e)
        }
```

## 6. エラー処理戦略

文書処理中に発生する様々なエラーに対応するための戦略です。

### 6.1 エラータイプとハンドリング

| エラータイプ | 対応戦略 |
|-------------|---------|
| ファイル破損 | 早期検出とユーザー通知、部分的に読み取り可能な場合は継続 |
| テキスト抽出失敗 | 代替エンジンでの再試行、OCRへのフォールバック |
| 構造解析エラー | 部分的な構造を保持し、エラー箇所をマーキング |
| 数式認識失敗 | 画像として保持し、ユーザーによる手動修正を可能に |
| メモリ不足 | 文書の分割処理、リソース管理の動的調整 |
| タイムアウト | 処理の分割と段階的実行、長時間ジョブの管理 |

### 6.2 部分的結果の保存

**実装アプローチ**:
- 段階ごとの中間結果の保存
- 処理可能な部分の優先的な完了
- エラー箇所のスキップと記録
- 再処理が必要な部分の特定

## 7. 性能最適化

大規模文書や複雑な数式を含む文書の処理性能を最適化する戦略です。

### 7.1 並列処理

**実装アプローチ**:
- ページ単位の並列処理
- セクション単位の並列処理
- マルチプロセス/マルチスレッドの活用
- 分散処理システムの利用（大規模文書向け）

### 7.2 キャッシュ戦略

**実装アプローチ**:
- 中間処理結果のキャッシュ
- 類似パターンの処理結果再利用
- 頻繁に参照される文書の処理結果の優先キャッシュ
- キャッシュの有効期限と更新ポリシー

### 7.3 リソース管理

**実装アプローチ**:
- 処理ジョブの優先順位付け
- 文書サイズと複雑さに基づくリソース割り当て
- 動的なリソーススケーリング
- バックグラウンド処理とオンデマンド処理の使い分け

## 8. 拡張性と今後の計画

### 8.1 新規フォーマット対応

**計画**:
- LaTeX文書の直接サポート
- HTML/XML文書の対応
- EPUBなど電子書籍フォーマットのサポート
- 複数ファイルからなる文書のサポート

### 8.2 機能拡張

**計画**:
- 高度な表解析機能の追加
- 数式の意味理解と操作
- 図のコンテンツ解析と分類
- 多言語文書の拡張サポート
- 引用ネットワークの構築と分析
