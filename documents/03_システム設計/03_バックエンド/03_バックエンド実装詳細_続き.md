# バックエンド実装詳細（続き）: LLM学術文書支援システム

## 3. LLM API連携

### 3.1 Claude APIクライアント

```python
# llm_service/app/services/claude.py
import asyncio
import json
from typing import AsyncGenerator, Dict, List, Optional, Union
import aiohttp
from app.core.config import settings
from app.models.chat import ChatMessage

class ClaudeClient:
    """Anthropic Claude APIクライアント"""
    
    def __init__(self):
        self.api_key = settings.ANTHROPIC_API_KEY
        self.api_url = "https://api.anthropic.com/v1/messages"
        self.model = settings.ANTHROPIC_MODEL  # "claude-3-opus-20240229" など
    
    async def _make_request(self, messages: List[Dict], system: Optional[str] = None, 
                           stream: bool = False, max_tokens: int = 4000) -> Dict:
        """Claude APIにリクエストを送信"""
        headers = {
            "x-api-key": self.api_key,
            "anthropic-version": "2023-06-01",
            "content-type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": messages,
            "max_tokens": max_tokens,
        }
        
        if system:
            payload["system"] = system
            
        if stream:
            payload["stream"] = True
            
        async with aiohttp.ClientSession() as session:
            async with session.post(self.api_url, headers=headers, json=payload) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"API request failed with status {response.status}: {error_text}")
                
                if stream:
                    return response  # ストリーミングの場合はレスポンスオブジェクトを返す
                else:
                    return await response.json()
    
    async def generate_response(self, messages: List[ChatMessage], 
                              system_message: Optional[str] = None,
                              max_tokens: int = 4000) -> str:
        """メッセージリストからレスポンスを生成"""
        api_messages = [
            {"role": msg.role, "content": msg.content}
            for msg in messages
        ]
        
        response = await self._make_request(api_messages, system_message, False, max_tokens)
        return response["content"][0]["text"]
    
    async def generate_stream(self, messages: List[ChatMessage], 
                            system_message: Optional[str] = None,
                            max_tokens: int = 4000) -> AsyncGenerator[str, None]:
        """ストリーミングレスポンスを生成するジェネレータ"""
        api_messages = [
            {"role": msg.role, "content": msg.content}
            for msg in messages
        ]
        
        response = await self._make_request(api_messages, system_message, True, max_tokens)
        
        async for line in response.content.iter_lines():
            if not line:
                continue
                
            if line.startswith(b"data: "):
                data_str = line[6:].decode("utf-8")
                if data_str == "[DONE]":
                    break
                    
                try:
                    data = json.loads(data_str)
                    if data["type"] == "content_block_delta" and data["delta"]["type"] == "text_delta":
                        yield data["delta"]["text"]
                except (json.JSONDecodeError, KeyError) as e:
                    print(f"Error parsing stream data: {e}")
```

### 3.2 OpenAI APIクライアント

```python
# llm_service/app/services/openai.py
import asyncio
import json
from typing import AsyncGenerator, Dict, List, Optional, Union
import aiohttp
from app.core.config import settings
from app.models.chat import ChatMessage

class OpenAIClient:
    """OpenAI API クライアント"""
    
    def __init__(self):
        self.api_key = settings.OPENAI_API_KEY
        self.api_url = "https://api.openai.com/v1/chat/completions"
        self.model = settings.OPENAI_MODEL  # "gpt-4" など
    
    async def _make_request(self, messages: List[Dict], 
                          stream: bool = False, max_tokens: int = 4000) -> Dict:
        """OpenAI APIにリクエストを送信"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": messages,
            "max_tokens": max_tokens,
        }
        
        if stream:
            payload["stream"] = True
            
        async with aiohttp.ClientSession() as session:
            async with session.post(self.api_url, headers=headers, json=payload) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"API request failed with status {response.status}: {error_text}")
                
                if stream:
                    return response  # ストリーミングの場合はレスポンスオブジェクトを返す
                else:
                    return await response.json()
    
    async def generate_response(self, messages: List[ChatMessage], 
                              max_tokens: int = 4000) -> str:
        """メッセージリストからレスポンスを生成"""
        api_messages = []
        
        for msg in messages:
            api_message = {"role": msg.role, "content": msg.content}
            api_messages.append(api_message)
        
        response = await self._make_request(api_messages, False, max_tokens)
        return response["choices"][0]["message"]["content"]
    
    async def generate_stream(self, messages: List[ChatMessage], 
                            max_tokens: int = 4000) -> AsyncGenerator[str, None]:
        """ストリーミングレスポンスを生成するジェネレータ"""
        api_messages = []
        
        for msg in messages:
            api_message = {"role": msg.role, "content": msg.content}
            api_messages.append(api_message)
        
        response = await self._make_request(api_messages, True, max_tokens)
        
        async for line in response.content.iter_lines():
            if not line:
                continue
                
            if line.startswith(b"data: "):
                data_str = line[6:].decode("utf-8")
                
                if data_str == "[DONE]":
                    break
                    
                try:
                    data = json.loads(data_str)
                    if "choices" in data and len(data["choices"]) > 0:
                        delta = data["choices"][0].get("delta", {})
                        if "content" in delta:
                            yield delta["content"]
                except (json.JSONDecodeError, KeyError) as e:
                    print(f"Error parsing stream data: {e}")
```

### 3.3 ベクトル埋め込み

```python
# llm_service/app/services/embeddings.py
import numpy as np
from typing import List, Dict, Any
import aiohttp
from app.core.config import settings
from app.db.mongodb import get_database

async def get_embeddings(text: str) -> List[float]:
    """OpenAI API を使用してテキストの埋め込みベクトルを取得"""
    api_url = "https://api.openai.com/v1/embeddings"
    headers = {
        "Authorization": f"Bearer {settings.OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "text-embedding-3-small",
        "input": text
    }
    
    async with aiohttp.ClientSession() as session:
        async with session.post(api_url, headers=headers, json=payload) as response:
            if response.status != 200:
                error_text = await response.text()
                raise Exception(f"Embedding API request failed: {error_text}")
            
            result = await response.json()
            return result["data"][0]["embedding"]

async def similarity_search(document_id: str, query_embedding: List[float], limit: int = 5) -> List[Dict[str, Any]]:
    """ベクトル類似度検索を実行"""
    db = await get_database()
    collection = db.document_sections
    
    # ベクトル検索クエリ
    pipeline = [
        {
            "$match": {
                "document_id": document_id
            }
        },
        {
            "$vectorSearch": {
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": limit * 3,
                "limit": limit,
                "index": "vector_index",
            }
        },
        {
            "$project": {
                "_id": 0,
                "id": 1,
                "title": 1,
                "content": 1,
                "score": { "$meta": "vectorSearchScore" }
            }
        }
    ]
    
    results = await collection.aggregate(pipeline).to_list(length=limit)
    return results

async def store_section_embeddings(section_id: str, embedding: List[float]) -> None:
    """セクションの埋め込みベクトルをデータベースに格納"""
    db = await get_database()
    collection = db.document_sections
    
    await collection.update_one(
        {"id": section_id},
        {"$set": {"embedding": embedding}},
        upsert=False
    )

async def store_document_embeddings(document_id: str, embedding: List[float]) -> None:
    """文書全体の埋め込みベクトルをデータベースに格納"""
    db = await get_database()
    collection = db.documents
    
    await collection.update_one(
        {"_id": document_id},
        {"$set": {"embedding": embedding}},
        upsert=False
    )
```

## 4. PDF処理と構造化

### 4.1 PDFテキスト抽出

```python
# document_service/app/processors/pdf_processor.py
from dataclasses import dataclass
from typing import List, Optional, Dict, Tuple
import fitz  # PyMuPDF
import re

@dataclass
class TextExtractionResult:
    """PDFテキスト抽出の結果"""
    full_text: str
    page_texts: List[str]
    structure_hints: Dict[str, List[Tuple[int, str]]]  # ヘッダー情報など

def extract_text_from_pdf(file_path: str) -> TextExtractionResult:
    """PDFからテキストを抽出し、構造情報を収集"""
    doc = fitz.open(file_path)
    
    page_texts = []
    headings = []
    full_text = ""
    
    # ヘッダーを検出するための正規表現パターン
    heading_patterns = [
        # 数字付きセクション (例: "1. Introduction", "2.3 Methods")
        r'^(\d+(?:\.\d+)*)\s+([A-Z][^\n]+)$',
        # 非数字ヘッダー (例: "Abstract", "References")
        r'^([A-Z][A-Za-z\s]{2,20})$'
    ]
    
    for page_num, page in enumerate(doc):
        # テキストブロック単位で抽出
        blocks = page.get_text("dict")["blocks"]
        page_text = ""
        
        for block in blocks:
            if "lines" not in block:
                continue
                
            for line in block["lines"]:
                line_text = "".join(span["text"] for span in line["spans"])
                
                # ヘッダー検出
                for pattern in heading_patterns:
                    match = re.match(pattern, line_text.strip())
                    if match:
                        if len(match.groups()) == 2:
                            section_num, heading_text = match.groups()
                            headings.append((page_num, f"{section_num} {heading_text}"))
                        else:
                            heading_text = match.group(1)
                            headings.append((page_num, heading_text))
                
                page_text += line_text + "\n"
        
        page_texts.append(page_text)
        full_text += page_text + "\n\n"
    
    return TextExtractionResult(
        full_text=full_text,
        page_texts=page_texts,
        structure_hints={"headings": headings}
    )
```

### 4.2 文書構造解析

```python
# document_service/app/processors/structure_analyzer.py
from typing import List, Dict, Any, Optional
import re
import uuid
from app.processors.pdf_processor import TextExtractionResult

class DocumentSection:
    """文書のセクションを表すクラス"""
    def __init__(self, id: str, title: str, level: int, start_page: int, parent_id: Optional[str] = None):
        self.id = id
        self.title = title
        self.level = level
        self.start_page = start_page
        self.parent_id = parent_id
        self.children: List[DocumentSection] = []
    
    def to_dict(self) -> Dict[str, Any]:
        """辞書形式に変換"""
        return {
            "id": self.id,
            "title": self.title,
            "level": self.level,
            "start_page": self.start_page,
            "parent_id": self.parent_id
        }

def analyze_document_structure(extraction_result: TextExtractionResult) -> Dict[str, Any]:
    """文書の構造を解析し、階層的なセクション構造を構築"""
    headings = extraction_result.structure_hints.get("headings", [])
    
    # セクションの階層構造を構築
    root_sections: List[DocumentSection] = []
    section_map: Dict[str, DocumentSection] = {}
    current_levels = [None] * 10  # 最大10階層まで対応
    
    for page_num, heading_text in headings:
        # セクション番号からレベルを判定
        section_match = re.match(r'^(\d+(?:\.\d+)*)\s+(.+)$', heading_text)
        
        if section_match:
            section_num, title = section_match.groups()
            parts = section_num.split('.')
            level = len(parts)
            
            section_id = str(uuid.uuid4())
            parent_id = None
            
            # 親セクションを特定
            if level > 1:
                parent_level = level - 1
                parent_section = current_levels[parent_level]
                if parent_section:
                    parent_id = parent_section.id
            
            # セクション作成
            section = DocumentSection(
                id=section_id,
                title=heading_text,
                level=level,
                start_page=page_num,
                parent_id=parent_id
            )
            
            # 階層構造に追加
            if parent_id and parent_id in section_map:
                section_map[parent_id].children.append(section)
            else:
                root_sections.append(section)
            
            # マップに追加
            section_map[section_id] = section
            current_levels[level] = section
            
            # このレベルより下の現在のセクションをクリア
            for i in range(level + 1, len(current_levels)):
                current_levels[i] = None
        else:
            # 番号なしのヘッダー（Abstract, Referencesなど）
            section_id = str(uuid.uuid4())
            section = DocumentSection(
                id=section_id,
                title=heading_text,
                level=1,
                start_page=page_num
            )
            root_sections.append(section)
            section_map[section_id] = section
    
    # セクションの内容を平坦化したリストに変換
    flat_sections = []
    for section_id, section in section_map.items():
        flat_sections.append(section.to_dict())
    
    return {
        "pages": len(extraction_result.page_texts),
        "sections": flat_sections
    }
```

### 4.3 数式抽出

```python
# document_service/app/processors/math_extractor.py
from typing import List, Dict, Any
import re
from app.processors.pdf_processor import TextExtractionResult

def extract_equations(extraction_result: TextExtractionResult) -> List[Dict[str, Any]]:
    """PDFから数式を抽出"""
    equations = []
    
    # LaTeX数式の検出パターン
    inline_math_pattern = r'\$(.*?)\$'
    display_math_pattern = r'\$\$(.*?)\$\$'
    begin_equation_pattern = r'\\begin\{equation\}(.*?)\\end\{equation\}'
    
    # ページごとに処理
    for page_num, page_text in enumerate(extraction_result.page_texts):
        # インライン数式の検出
        inline_matches = re.finditer(inline_math_pattern, page_text)
        for match in inline_matches:
            equation_id = f"eq_inline_{page_num}_{match.start()}"
            latex = match.group(1)
            equations.append({
                "id": equation_id,
                "latex": latex,
                "page": page_num,
                "position": {
                    "start": match.start(),
                    "end": match.end()
                },
                "type": "inline"
            })
        
        # ディスプレイ数式の検出
        display_matches = re.finditer(display_math_pattern, page_text)
        for match in display_matches:
            equation_id = f"eq_display_{page_num}_{match.start()}"
            latex = match.group(1)
            equations.append({
                "id": equation_id,
                "latex": latex,
                "page": page_num,
                "position": {
                    "start": match.start(),
                    "end": match.end()
                },
                "type": "display"
            })
        
        # equation環境の検出
        equation_matches = re.finditer(begin_equation_pattern, page_text, re.DOTALL)
        for match in equation_matches:
            equation_id = f"eq_numbered_{page_num}_{match.start()}"
            latex = match.group(1)
            equations.append({
                "id": equation_id,
                "latex": latex,
                "page": page_num,
                "position": {
                    "start": match.start(),
                    "end": match.end()
                },
                "type": "numbered"
            })
    
    return equations
```

## 5. ストリーミングレスポンスハンドラ

```python
# llm_service/app/api/v1/chat.py
from fastapi import APIRouter, Depends, BackgroundTasks, HTTPException
from fastapi.responses import StreamingResponse
from sse_starlette.sse import EventSourceResponse
from app.schemas.chat import ChatMessageCreate
from app.services.claude import ClaudeClient
from app.services.context_builder import ContextBuilder
from app.services.prompt_templates import prompt_template_manager
from app.crud.chat import create_chat_message, get_chat_session
from app.api.deps import get_current_user

router = APIRouter()
claude_client = ClaudeClient()

@router.post("/chats/{chat_id}/messages/stream")
async def stream_chat_message(
    chat_id: str,
    message: ChatMessageCreate,
    background_tasks: BackgroundTasks,
    current_user = Depends(get_current_user)
):
    """ストリーミング形式でチャットメッセージに応答"""
    # チャットセッション取得
    chat = await get_chat_session(chat_id)
    if not chat:
        raise HTTPException(status_code=404, detail="Chat session not found")
    
    # ユーザーメッセージをDBに保存
    user_message = await create_chat_message(
        chat_id=chat_id,
        content=message.content,
        role="user",
        user_id=current_user.id
    )
    
    # コンテキスト構築
    context_builder = ContextBuilder(document_id=chat.document_id)
    document_context = await context_builder.build_context_for_query(message.content)
    
    # チャット履歴取得と整形
    history = await get_chat_history(chat_id)
    formatted_messages = format_chat_messages(history)
    
    # システムメッセージ生成
    system_message = create_system_message(document_context)
    
    # ストリーミングレスポンス生成関数
    async def generate():
        full_response = ""
        async for text_chunk in claude_client.generate_stream(
            messages=formatted_messages,
            system_message=system_message
        ):
            full_response += text_chunk
            yield f"data: {json.dumps({'text': text_chunk})}\n\n"
        
        # レスポンス完了後にメッセージをDBに保存（バックグラウンドタスク）
        background_tasks.add_task(
            save_assistant_response,
            chat_id=chat_id,
            content=full_response,
            referenced_sections=document_context.sections,
            user_id=current_user.id
        )
        
        yield f"data: [DONE]\n\n"
    
    return EventSourceResponse(generate())

async def save_assistant_response(chat_id: str, content: str, referenced_sections: List[str], user_id: str):
    """バックグラウンドでアシスタントの応答を保存"""
    await create_chat_message(
        chat_id=chat_id,
        content=content,
        role="assistant",
        user_id=user_id,
        referenced_sections=referenced_sections
    )
```

## 6. APIルーターの実装

```python
# document_service/app/api/v1/documents.py
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form, BackgroundTasks
from fastapi.responses import JSONResponse
from typing import List, Optional
from app.schemas.document import DocumentCreate, DocumentResponse, DocumentList
from app.crud.document import create_document, get_document, get_documents_by_project
from app.tasks.document_processing import process_uploaded_document
from app.storage.s3 import upload_file_to_s3
from app.api.deps import get_current_user, get_db
from app.models.user import User

router = APIRouter()

@router.post("/{project_id}/documents", response_model=DocumentResponse)
async def upload_document(
    project_id: str,
    background_tasks: BackgroundTasks,
    title: str = Form(...),
    description: Optional[str] = Form(None),
    file: UploadFile = File(...),
    current_user: User = Depends(get_current_user),
    db = Depends(get_db)
):
    """文書をアップロードし処理キューに追加"""
    # ファイル形式チェック
    if not file.content_type in ["application/pdf", "image/jpeg", "image/png"]:
        raise HTTPException(status_code=400, detail="Only PDF and image files are supported")
    
    # S3にファイルをアップロード
    file_path = await upload_file_to_s3(file, project_id)
    
    # ドキュメント情報をDBに保存
    document = await create_document(
        db=db,
        data=DocumentCreate(
            title=title,
            description=description,
            project_id=project_id,
            file_type=file.content_type,
            file_path=file_path,
            original_filename=file.filename,
            uploaded_by=current_user.id
        )
    )
    
    # 非同期処理タスクを開始
    background_tasks.add_task(process_uploaded_document, str(document.id))
    
    return DocumentResponse(
        id=str(document.id),
        title=document.title,
        description=document.description,
        file_type=document.file_type,
        processing_status="pending",
        upload_date=document.upload_date
    )
```

## 7. Beanie ODMによるMongoDBモデル定義

```python
# document_service/app/models/document.py
from typing import List, Optional, Dict, Any
from datetime import datetime
from pydantic import Field
from beanie import Document, Link
from app.models.user import User
from app.models.project import Project

class DocumentMetadata(Document):
    """文書メタデータモデル"""
    authors: Optional[List[str]] = None
    publication_date: Optional[datetime] = None
    journal: Optional[str] = None
    doi: Optional[str] = None
    keywords: Optional[List[str]] = None

class DocumentStructure(Document):
    """文書構造モデル"""
    pages: int
    sections: List[Dict[str, Any]]

class DocumentContent(Document):
    """文書内容モデル"""
    full_text: str
    page_texts: List[str]
    equations: Optional[List[Dict[str, Any]]] = None
    figures: Optional[List[Dict[str, Any]]] = None
    tables: Optional[List[Dict[str, Any]]] = None
    references: Optional[List[Dict[str, Any]]] = None

class Document(Document):
    """文書モデル"""
    title: str
    description: Optional[str] = None
    project_id: str = Field(..., index=True)
    file_type: str  # "pdf", "image/jpeg", etc.
    file_path: str
    original_filename: str
    file_size: Optional[int] = None
    uploaded_by: str  # user_id
    upload_date: datetime = Field(default_factory=datetime.utcnow)
    processing_status: str = "pending"  # "pending", "processing", "completed", "failed"
    error_message: Optional[str] = None
    
    # リレーションシップ (Beanie ODM)
    project: Optional[Link[Project]] = None
    uploader: Optional[Link[User]] = None
    
    # 拡張データ
    metadata: Optional[DocumentMetadata] = None
    structure: Optional[DocumentStructure] = None
    content: Optional[DocumentContent] = None
    vector_id: Optional[str] = None
    
    class Settings:
        name = "documents"
        indexes = [
            [("project_id", 1)],
            [("title", "text"), ("description", "text")],
            [("processing_status", 1)]
        ]
```

## 8. 設定とデータベース初期化

```python
# document_service/app/core/config.py
from typing import List, Optional
from pydantic import BaseSettings, AnyHttpUrl

class Settings(BaseSettings):
    """アプリケーション設定"""
    # API設定
    API_V1_STR: str = "/api/v1"
    PROJECT_NAME: str = "LLM学術文書支援システム"
    
    # CORS設定
    BACKEND_CORS_ORIGINS: List[AnyHttpUrl] = []
    
    # MongoDB設定
    MONGODB_URL: str
    MONGODB_DB_NAME: str = "llm_academic_assist"
    
    # Redis設定
    REDIS_HOST: str = "redis"
    REDIS_PORT: int = 6379
    
    # ストレージ設定
    STORAGE_TYPE: str = "s3"  # "s3" or "local"
    S3_BUCKET_NAME: str
    S3_REGION: str
    AWS_ACCESS_KEY_ID: str
    AWS_SECRET_ACCESS_KEY: str
    
    # JWT設定
    SECRET_KEY: str
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    
    # LLM設定
    ANTHROPIC_API_KEY: str
    ANTHROPIC_MODEL: str = "claude-3-opus-20240229"
    OPENAI_API_KEY: str
    OPENAI_MODEL: str = "gpt-4"
    
    class Config:
        env_file = ".env"
        case_sensitive = True

settings = Settings()

# document_service/app/db/mongodb.py
from motor.motor_asyncio import AsyncIOMotorClient
from beanie import init_beanie
from app.core.config import settings
from app.models.user import User
from app.models.project import Project
from app.models.document import Document, DocumentMetadata, DocumentStructure, DocumentContent

async def init_db():
    """データベース接続とモデル初期化"""
    client = AsyncIOMotorClient(settings.MONGODB_URL)
    db = client[settings.MONGODB_DB_NAME]
    
    # Beanieモデルの初期化
    await init_beanie(
        database=db,
        document_models=[
            User,
            Project,
            Document,
            DocumentMetadata,
            DocumentStructure,
            DocumentContent
        ]
    )
    
    return db

async def get_database():
    """データベース接続を取得"""
    client = AsyncIOMotorClient(settings.MONGODB_URL)
    return client[settings.MONGODB_DB_NAME]
```
